{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Transaction Statistical Analysis - Data Exploration Framework\n",
    "\n",
    "This notebook provides a comprehensive Python environment setup and data exploration framework for fraud transaction statistical analysis.\n",
    "\n",
    "## Objective\n",
    "- Load and explore transaction_fraud_data.parquet\n",
    "- Perform comprehensive data exploration and preprocessing\n",
    "- Generate data quality reports\n",
    "- Create reusable functions for statistical analysis preparation\n",
    "\n",
    "## Libraries and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical analysis libraries\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest, shapiro, kstest, jarque_bera\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "import pingouin as pg\n",
    "from diptest import diptest\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Date and time handling\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# System and utility libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import json\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print('âœ… All libraries imported successfully!')\n",
    "print(f'ğŸ“Š Pandas version: {pd.__version__}')\n",
    "print(f'ğŸ”¢ NumPy version: {np.__version__}')\n",
    "print(f'ğŸ“ˆ SciPy version: {stats.__version__ if hasattr(stats, \"__version__\") else \"Available\"}')\n",
    "print(f'ğŸ¨ Matplotlib version: {plt.matplotlib.__version__}')\n",
    "print(f'ğŸŒŠ Seaborn version: {sns.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Exploration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_fraud_data(n_samples: int = 10000, fraud_rate: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a sample fraud transaction dataset matching the schema described in README.md\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of transactions to generate\n",
    "    fraud_rate : float\n",
    "        Proportion of fraudulent transactions (0-1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Generated fraud transaction dataset\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Generate base data\n",
    "    data = {\n",
    "        'transaction_id': [f'TXN_{i:08d}' for i in range(n_samples)],\n",
    "        'customer_id': [f'CUST_{np.random.randint(1, n_samples//5):06d}' for _ in range(n_samples)],\n",
    "        'card_number': np.random.randint(1000000000000000, 9999999999999999, n_samples),\n",
    "        'timestamp': pd.date_range('2024-09-30', '2024-10-30', periods=n_samples),\n",
    "        'vendor_category': np.random.choice(['Retail', 'Travel', 'Entertainment', 'Healthcare', 'Education', 'Fuel', 'Restaurant'], n_samples),\n",
    "        'vendor_type': np.random.choice(['online', 'offline', 'premium', 'fastfood'], n_samples),\n",
    "        'vendor': [f'Vendor_{np.random.randint(1, 1000):03d}' for _ in range(n_samples)],\n",
    "        'amount': np.random.lognormal(3, 1.5, n_samples),  # Log-normal distribution for realistic amounts\n",
    "        'currency': np.random.choice(['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD'], n_samples, p=[0.4, 0.2, 0.1, 0.1, 0.1, 0.1]),\n",
    "        'country': np.random.choice(['USA', 'UK', 'Germany', 'France', 'Japan', 'Canada', 'Australia'], n_samples),\n",
    "        'city': [f'City_{np.random.randint(1, 500):03d}' for _ in range(n_samples)],\n",
    "        'city_size': np.random.choice(['small', 'medium', 'large'], n_samples, p=[0.3, 0.4, 0.3]),\n",
    "        'card_type': np.random.choice(['Basic Credit', 'Gold Credit', 'Platinum Credit', 'Debit'], n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "        'is_card_present': np.random.choice([True, False], n_samples, p=[0.6, 0.4]),\n",
    "        'device': np.random.choice(['Chrome', 'Safari', 'iOS App', 'Android App', 'Firefox'], n_samples),\n",
    "        'channel': np.random.choice(['web', 'mobile', 'pos'], n_samples, p=[0.4, 0.3, 0.3]),\n",
    "        'device_fingerprint': [f'FP_{np.random.randint(1000000, 9999999):07d}' for _ in range(n_samples)],\n",
    "        'ip_address': [f'{np.random.randint(1, 255)}.{np.random.randint(1, 255)}.{np.random.randint(1, 255)}.{np.random.randint(1, 255)}' for _ in range(n_samples)],\n",
    "        'is_outside_home_country': np.random.choice([True, False], n_samples, p=[0.15, 0.85]),\n",
    "        'is_high_risk_vendor': np.random.choice([True, False], n_samples, p=[0.2, 0.8]),\n",
    "        'is_weekend': np.random.choice([True, False], n_samples, p=[0.3, 0.7])\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add last_hour_activity as nested structure\n",
    "    df['last_hour_activity'] = [\n",
    "        {\n",
    "            'num_transactions': np.random.randint(1, 10),\n",
    "            'total_amount': np.random.uniform(10, 1000),\n",
    "            'unique_merchants': np.random.randint(1, 5),\n",
    "            'unique_countries': np.random.randint(1, 3),\n",
    "            'max_single_amount': np.random.uniform(50, 500)\n",
    "        } for _ in range(n_samples)\n",
    "    ]\n",
    "    \n",
    "    # Generate fraud labels with realistic patterns\n",
    "    fraud_indices = np.random.choice(n_samples, int(n_samples * fraud_rate), replace=False)\n",
    "    df['is_fraud'] = False\n",
    "    df.loc[fraud_indices, 'is_fraud'] = True\n",
    "    \n",
    "    # Make fraudulent transactions more realistic\n",
    "    # Higher amounts for fraud\n",
    "    df.loc[df['is_fraud'], 'amount'] *= np.random.uniform(2, 5, sum(df['is_fraud']))\n",
    "    # More likely to be outside home country\n",
    "    df.loc[df['is_fraud'], 'is_outside_home_country'] = np.random.choice([True, False], sum(df['is_fraud']), p=[0.7, 0.3])\n",
    "    # More likely to be high risk vendor\n",
    "    df.loc[df['is_fraud'], 'is_high_risk_vendor'] = np.random.choice([True, False], sum(df['is_fraud']), p=[0.8, 0.2])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fraud_data(file_path: str = 'transaction_fraud_data.parquet') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load fraud transaction data from parquet file or create sample data if file doesn't exist\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the parquet file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Fraud transaction dataset\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f'ğŸ“ Loading data from {file_path}...')\n",
    "        df = pd.read_parquet(file_path)\n",
    "        print(f'âœ… Data loaded successfully! Shape: {df.shape}')\n",
    "    else:\n",
    "        print(f'âš ï¸  File {file_path} not found. Creating sample data...')\n",
    "        df = create_sample_fraud_data()\n",
    "        # Save the sample data\n",
    "        df.to_parquet(file_path, index=False)\n",
    "        print(f'âœ… Sample data created and saved to {file_path}! Shape: {df.shape}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df_fraud = load_fraud_data()\n",
    "print(f'\\nğŸ“Š Dataset loaded with shape: {df_fraud.shape}')\n",
    "print(f'ğŸ“‹ Columns: {list(df_fraud.columns)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}